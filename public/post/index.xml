<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Consulting Statistician</title>
    <link>/post/</link>
    <description>Recent content in Posts on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0530</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Web-scraping ODI Cricket World Cup Matches </title>
      <link>/post/webscraping/webscraping/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/webscraping/webscraping/</guid>
      <description>IntroductionWebscrapingIntroductionWorld Cup matches are now in action as all initial matches are over, while semi-final and finalmatches are to come. Sri Lanka is not in the final four, but not at the bottom as well thankfullywe ended up in sixth place.
It should be noted that not all world cups are the same, earlier it was 60 overs for a team now it is 50overs.</description>
    </item>
    
    <item>
      <title>Week 27: Media Franchise Powerhouses</title>
      <link>/post/tidytuesday2019/week27/week27/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week27/week27/</guid>
      <description>Revenue Category and Original Media by Cow PlotRevenue Category and Original Media by AnimationsRevenue Category and Original Media by rayshaderRevenue Category In DecadesRevenue Category In Decades but with Total Revenuemedia_franchises &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv&amp;quot;)library(tidyverse)library(cowplot)library(rayshader)library(ggmosaic)library(gganimate)library(viridis)Using rayshader for the first time, Also cowplot package to combine two plots. Also, Manga has the highest total revenue in Original Media and second place is for Video game, others are significantly low.</description>
    </item>
    
    <item>
      <title>Week 26: Unidentified Flying Objects</title>
      <link>/post/tidytuesday2019/week26/week26/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week26/week26/</guid>
      <description>Timely changes for country and shapeYearly count changesMonthly count changesHourly count changesYearly Count changes for CountriesMonthly Count changes for CountriesHourly Count changes for CountriesDecade wise UFO shape changesDocumented Year and Origin YearYear vs Encounter LengthHour vs Encounter Lengthufo_sightings &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv&amp;quot;)library(tidyverse)library(gganimate)library(ggthemes)library(lubridate)library(ggforce)library(ggthemr)GitHub
USA and Canada has lot of sightings and most of them in mid year.</description>
    </item>
    
    <item>
      <title>Week 25: Birds, Ohhhh Canada </title>
      <link>/post/tidytuesday2019/week25/week25/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week25/week25/</guid>
      <description>Year with How many counted, How many counted by Hour and Total HoursYear and Total Hours by decadeYear and How many Counted by decadeYear and How many Hours Counted by Hour for decadeTop 10 Species with how many countedTop 10 Species with how many counted by yearTop 10 Species with how many counted by decadeTop 10 How many counted by hoursTop 10 Species with how many counted by hours for yearTop 10 Species with how many counted by hours for decadebird_counts &amp;lt;- readr::read_csv(&amp;quot;https://raw.</description>
    </item>
    
    <item>
      <title>Week 24: Meteorite Data</title>
      <link>/post/tidytuesday2019/week24/week24/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week24/week24/</guid>
      <description>Meteorites over the YearMeteorites and ClassesThis week has data for Meteors from 8th century to year 2013(well 2101 is an error).
So I have used the packages tidyverse,gganimate,maps and ggthemes to make this moreinteresting. There are three plots which I have generated, two of them are inspiredby others.
meteorites &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv&amp;quot;)library(tidyverse)library(gganimate)library(maps)library(ggthemes)Meteorites over the YearBased on the below tweet I was inspired to creata a similar plot which is animated byyears.</description>
    </item>
    
    <item>
      <title>Week 23 : Ramen Ratings</title>
      <link>/post/tidytuesday2019/week23/week23/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week23/week23/</guid>
      <description>ramen_ratings &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv&amp;quot;)library(tidyverse)library(gganimate)library(ggthemes)I have not posted regarding #TidyTuesday in a while, so here it is. It is allabout manipulating the dataset and generating necessary plots.
DataGitHub Code
Just an animated plot where for the top 10 brands how stars change with style and country. Ramen is with highest ratings in Japan, Taiwan and South Korea. #TidyTuesday GitHub Code : https://t.co/lPQrYK8aoN pic.twitter.com/IQ3okDflYK
&amp;mdash; Amalan Mahendran (@Amalan_Con_Stat) June 5, 2019  ramen_ratings %&amp;gt;%count(stars,sort = TRUE) %&amp;gt;%ggplot(.</description>
    </item>
    
    <item>
      <title>South Park Text Analytics Shiny App</title>
      <link>/post/southpark_rshiny/southpark_rshiny/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/southpark_rshiny/southpark_rshiny/</guid>
      <description>Shiny App of Text Analytics for South Park Tv show.No Inputs needed to generate Plots or ResultsTrivia Sub TabLines Sub TabWords Sub TabSpecial Words Sub TabRatings and Votes from IMDB Sub TabSentiment Analysis Sub TabBigram and Trigram Analysis Sub TabInputs needed from the user to generate Plots and ResultsCompare Two Seasons Tab.Compare Two Characters Tab.Compare Two Characters but Same Season Tab.</description>
    </item>
    
    <item>
      <title>Week 15 : Tennis Tournaments</title>
      <link>/post/tidytuesday2019/week15/week15/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week15/week15/</guid>
      <description>library(readr)library(tidyverse)library(lubridate)library(gganimate)player_dob &amp;lt;- read_csv(&amp;quot;player_dob.csv&amp;quot;, col_types = cols(date_of_birth = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), date_of_first_title = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;)))grand_slams &amp;lt;- read_csv(&amp;quot;grand_slams.csv&amp;quot;, col_types = cols(gender = col_factor(levels = c(&amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;)), rolling_win_count = col_integer(), tournament_date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), year = col_integer()))grand_slam_timeline &amp;lt;- read_csv(&amp;quot;grand_slam_timeline.csv&amp;quot;, col_types = cols(gender = col_factor(levels = c(&amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;)), year = col_integer()))Winning the Wimbledon as your first grand slam looks very thin than other three tournaments. Also among the top 10 most grand slam winners Roger Federer and Chris Evert have reached semi-finals only a lot of times.</description>
    </item>
    
    <item>
      <title>Week 14 : Seattle Bikes</title>
      <link>/post/tidytuesday2019/week14/week14/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week14/week14/</guid>
      <description>Crossing vs Direction with Morning or Evening for EverydayAverag Bike Count in Different Time LapsMonthly Average Bike Count for Everyday with AM or PMDay by Average Bike Count for Everyday with AM or PMHourly Average Bike Count for Every Month with AM or PMPedestrian Count With Different Time LapsMonthly Pedestrian Count for Everyday with AM or PM when TRUEMonthly Pedestrian Count for Everyday with AM or PM when FALSEDay by Pedestrian Count for Everyday with AM or PM when TRUEDay by Pedestrian Count for Everyday with AM or PM when FALSEHourly Pedestrian Count for Every Month with AM or PM when TRUEHourly Pedestrian Count for Every Month with AM or PM when FALSEAverage Bike Count with CrossingsAverage Bike Count with DirectionsAverage Bike Count with Crossings by DayAverage Bike Count with Directions by Daylibrary(tidyverse)library(dplyr)library(gganimate)library(ggthemr)library(splitstackshape)library(lubridate)library(readr)bike_traffic &amp;lt;- read_csv(&amp;quot;bike_traffic.</description>
    </item>
    
    <item>
      <title>Week 13 : Pets In Seattle</title>
      <link>/post/tidytuesday2019/week13/week13/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week13/week13/</guid>
      <description>Yearly ChangeZipcode Counts Over the YearsSpecies Counts Over the YearsPrimary Breed Over the YearsAnimals Name Over the YearsZipCode and ChoicesZipcode with choices of SpeciesZipcode with choices of Primary BreedZipcode with choices of Animals NamePrimary and Secondary Breed Choices Over the YearsSpecies and Name choices for Animalslibrary(readr)library(tidyverse)library(gganimate)library(splitstackshape)library(forcats)library(ggthemr)ggthemr(&amp;quot;flat dark&amp;quot;)seattle_pets &amp;lt;- read_csv(&amp;quot;seattle_pets.</description>
    </item>
    
    <item>
      <title>Week 11 : Board Games</title>
      <link>/post/tidytuesday2019/week11/week11/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week11/week11/</guid>
      <description>Minimum No of Players and Minimum Play TimeGeneralScrutinizedMore ScrutinizedMaximum No of Players and Maximmum Play TimeGeneralScrutinizedMore ScrutinizedMaximum No of Players and Average RatingGeneralScrutinizedMore ScrutinizedAverage Rating and Users RatedAnimatedNot AnimatedCategory and RatingGeneral and Category 1General and Category 2# load the packageslibrary(readr)library(tidyverse)library(tidylog)library(gganimate)library(splitstackshape)library(ggthemr)# load the themeggthemr(&amp;quot;chalk&amp;quot;)# load the databoard_games &amp;lt;- read_csv(&amp;quot;board_games.</description>
    </item>
    
    <item>
      <title>Week 10: Women in Workforce</title>
      <link>/post/tidytuesday2019/week10/week10/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week10/week10/</guid>
      <description>Earnings FemaleAll other age groupsEmployed GenderComparing Full Time with Part TimeMale Occupants with Full Time and Part Time WorkFemale Occupants with Full Time and Part Time WorkJobs GenderMajor CategoryMajor Category and Total WorkersMajor Category and Male WorkersMajor Category and Female WorkersMajor Category and Total Earnings Male WageMajor Category and Total Earnings Female WageMajor Category and Wage Percent for Female relative to MaleMinor CategoryMinor Category and Total WorkersMinor Category and Male WorkersMinor Category and Female WorkersMinor Category and Total Earnings Male WageMinor Category and Total Earnings Female WageMinor Category and Wage Percent for Female relative to MaleGitHub Code</description>
    </item>
    
    <item>
      <title>Week 9 : French Train Delays</title>
      <link>/post/tidytuesday2019/week9/week9/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week9/week9/</guid>
      <description># load the packageslibrary(readr)library(tidyverse)library(gganimate)library(ggalluvial)library(geomnet)library(ggthemr)# load the themeggthemr(&amp;quot;fresh&amp;quot;)# load the datasmall_trains &amp;lt;- read_csv(&amp;quot;small_trains.csv&amp;quot;)GitHub Code
Data set
When Journey Average Time increases the Total Number of Trips will decrease. Obviously. Code : https://t.co/qY2l10OraS #TidyTuesday pic.twitter.com/ZZn0l7E7WZ
&amp;mdash; Amalan Mahendran (@Amalan_Con_Stat) February 28, 2019  Network Graph for the French City TrainsSimply drawing a network graph to understand which french cities are mainly urban with capacity to trains arriving and leaving.</description>
    </item>
    
    <item>
      <title>Week 8 : Phds Awarded in USA between 2008 and 2017</title>
      <link>/post/tidytuesday2019/week8/week8/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week8/week8/</guid>
      <description>Broad FieldAll fieldsDropping Psychology and Social SciencesMajor FieldMajor Fields with Box plotMajor Fields without Psychology but still in a BoxplotMathematics and Computer SciencesMathematics and Computer Science as a Broad fieldMathematics and Computer Science as a Major FieldMajor Field of Mathematics and Computer Science but now all FieldsMajor Field, Field and Year For Mathematics and Computer Sciences# load the packageslibrary(tidyverse)library(ggthemr)library(readr)library(gganimate)library(ggridges)library(ggalluvial)ggthemr(&amp;quot;flat&amp;quot;)#load the dataphdlist &amp;lt;- read_csv(&amp;quot;phd_by_field.</description>
    </item>
    
    <item>
      <title>Sri Lanka and its affect on/in Journal Articles </title>
      <link>/post/slandjournal/slandjournal/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/slandjournal/slandjournal/</guid>
      <description>IntroductionPackages and IdeasCountry InformationRanking of Sri Lanka from 1996 to 2017Ranking of South Asian Region Countries from 1996 to 2017Documents , Citable Documents and Self Citations from Sri Lanka JournalsCitations per Document from Sri Lankan JournalsJournals from Sri LankaRank changes for Sri Lankan JournalsSJR values changing for Sri Lankan JournalsReferences per Document changing for Sri Lankan JournalsPublishers and Journals from Sri LankaTotal Documents and References for Journals from Sri LankaThree year time period for Journals from Sri LankaJournals and categoriesIntroduction“SCImago Journal and Country Rank provides valuable estimates of academic journals’ prestige.</description>
    </item>
    
    <item>
      <title>Tree of Binomial Distribution</title>
      <link>/post/binomialdistribution/binomialdistribution/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/binomialdistribution/binomialdistribution/</guid>
      <description>Binomial DistributionApplicationsBinomial Mixture DistributionsMain Groups for Binomial DistributionOther With No Sub-GroupsGrassia Binomial DistributionZero Modified Binomial DistributionDandekar’s Modified Binomial DistributionSimplex Binomial Mixture ModelDouble Binomial DistributionFinite Biomial MixturesBinomial Distribution of order KTruncated Binomial DistributionWeighted Binomial DistributionBinomial Not ParentHypergeometric + BinomialNegative Binomial + BinomialPoisson + BinomialAlternate Binomial DistributionsAdditive Binomial DistributionBeta-Correlated Binomial DistributionCOM-Poisson Binomial DistributionCorrelated Binomial DistributionMultiplicative Binomial DistributionNeyman Type A DistributionPoisson + Binomial + BetaPoisson + Poisson + Binomial + Beta or Poisson + Binomial + Poisson + BetaHermite DistributionBinomial + PoissonPoisson + BinomialBinomial ParentN/n , K and Y Mixturesp Transformed BinomialLog Inverse Distribution [0,1] DomainCumulative Distribution Functionp BinomialReferencesBinomial DistributionThe binomial distribution can be defined, using the binomial expansion</description>
    </item>
    
    <item>
      <title>Week 7: Spending On Science Stuff</title>
      <link>/post/tidytuesday2019/week7/week7/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week7/week7/</guid>
      <description>Climate Change ResearchEnergyFederal# load the packages library(readr)library(tidyverse)library(gganimate)library(dplyr)library(magrittr)# load the dataclimate &amp;lt;- read_csv(&amp;quot;climate_spending.csv&amp;quot;)energy &amp;lt;- read_csv(&amp;quot;energy_spending.csv&amp;quot;, col_types = cols(year = col_integer()))federal &amp;lt;- read_csv(&amp;quot;fed_r_d_spending.csv&amp;quot;)Even though I can go further and do an investigative plotting from the rest data it is not done here. I was more focused on the scientific notation values in the plotting and scales, which were bothering me a lot.</description>
    </item>
    
    <item>
      <title>Week 6 : Mortgage, Recession and States</title>
      <link>/post/tidytuesday2019/week6/week6/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week6/week6/</guid>
      <description>MortgageFixed Rate 30 Years from 1971 to 2018Fixed Rate 15 Years from 1991 to 2018Fees and Points of 30 Years from 1971 to 2018Fees and Points of 15 Years from 1991 to 2018StatesNew England RegionMideast RegionGreat Lakes RegionPlains RegionSoutheast RegionSouthwest RegionRocky Mountain RegionFar West Region# load the packageslibrary(readr)library(tidyverse)library(bbplot)library(gganimate)library(magrittr)library(lubridate)# load the datamortgage &amp;lt;- read_csv(&amp;quot;mortgage.</description>
    </item>
    
    <item>
      <title>Week 5: Dairy Products in USA</title>
      <link>/post/tidytuesday2019/week5/week-5-dairy-products-in-usa/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week5/week-5-dairy-products-in-usa/</guid>
      <description>IntroductionFluid Milk SalesState Milk ProductionUS States and Milk Production Over the YearsSumming States of Same Regions Over the YearsAveraging Regions Considering All the States Over the YearsCheeseCheese with OtherCheese with TotalCheese with known Type Names# load the packageslibrary(tidyverse)library(magrittr)library(ggthemr)library(readr)library(gganimate)library(usmap)# load the datafluid_milk_sales &amp;lt;- read_csv(&amp;quot;fluid_milk_sales.csv&amp;quot;)state_milk_production &amp;lt;- read_csv(&amp;quot;state_milk_production.csv&amp;quot;)clean_cheese &amp;lt;- read_csv(&amp;quot;clean_cheese.</description>
    </item>
    
    <item>
      <title>Build Your Own Website or Blog Using R, RStudio and R Packages.</title>
      <link>/post/personalwebsite/build-your-own-website-or-blog-using-r-rstudio-and-r-packages/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/personalwebsite/build-your-own-website-or-blog-using-r-rstudio-and-r-packages/</guid>
      <description>IntroductionMaterials“Making Websites with Rmarkdown and Blogdown by Yihui Xie.”“Up and Running with Blogdown by Alison Presmanes Hill.”“Rmarkdown Websites.”“How to make an RMarkdown Website by Nick Strayer &amp;amp; Lucy D’Agostino McGowan.”“Creating websites in R by Emily C Zabor.”“Getting Started with Blogdown by David Selby.”“Getting Started with Blogdown by Danielle Navarro.”“Blogdown by Peter’s Blog.”“Academic by George Cushen”“Happy Git and GitHub for the User.</description>
    </item>
    
    <item>
      <title>Olympic : Rshiny Approach</title>
      <link>/post/olympicrshiny/olympic-rshiny-approach/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/olympicrshiny/olympic-rshiny-approach/</guid>
      <description>IntroductionMaterial Useful for Rsiny DevelopmentHow To Use The Olympic Rshiny App ?Step 1Step 2Step 3Step 4Step 5Step 6Step 7Step 8IntroductionRshiny is very popular in the rstats community. The glamourous interface and functionality has helped for this level of popularity. In perspective of using an Rshiny App anyone can use it with minimal amount of knowledge.</description>
    </item>
    
    <item>
      <title>Week 4: Prison Data</title>
      <link>/post/tidytuesday2019/week4/week-4-prison-data/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week4/week-4-prison-data/</guid>
      <description>Prison SummaryPrison Summary With GenderPrison Summary with EthnicityPrison Summary with Other and TotalPretrial Summary with Gender and TotalComplete Data of Incarceration TrendsRape Crimes over the Years in States of Rural AreaRape Crimes over the Years in States of Small or Mid AreaRape Crimes over the Years in States of Suburban AreaRape Crimes over the Years in States of Urban Area# load the packageslibrary(readr)library(tidyverse)library(magrittr)library(gganimate)library(ggthemr)# load the themeggthemr(&amp;quot;flat dark&amp;quot;)# load the datapretrial_summary &amp;lt;- read_csv(&amp;quot;pretrial_summary.</description>
    </item>
    
    <item>
      <title>Week 3: Space Agencies and Launches</title>
      <link>/post/tidytuesday2019/week3/week-3-space-agencies-and-launches/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week3/week-3-space-agencies-and-launches/</guid>
      <description>AGENCIESAgency vs CountType vs CountClass vs CountAgency Type vs CountState Code vs CountLocation vs CountStart Year and End Year vs agencyLAUNCHESSuccess or Failure of these missions vs Category VariablesSuccess or Failure vs Launch YearSuccess or Failure vs Agency TypeSuccess or Failure vs State CodeState Code vs Category Over time for Success and Failure# load the packageslibrary(readr)library(tidyverse)library(ggalt)library(magrittr)library(dplyr)library(ggthemr)library(gganimate)# Load the Agency dataagencies&amp;lt;-read_csv(&amp;quot;agencies.</description>
    </item>
    
    <item>
      <title>Developing an R package</title>
      <link>/post/yourownpackage/developing-an-r-package/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/yourownpackage/developing-an-r-package/</guid>
      <description>IntroductionCredit to People of R Community1) Coding Standards (Coding to Understand)2) Package Structure3) DESCRIPTION file4) README file5) /R directory6) /data directory7) /tests directory8) /man directory9) NAMSESPACE file10) .Rbuildignore file11) .gitignore fileBuilding the PackageDistributing the PackageIntroductionR package development is no longer as it was before 2010 because now most of the work can be done by just a simple mouse-click or with the use of a function.</description>
    </item>
    
    <item>
      <title>Week 2: IMDB TV Shows Data</title>
      <link>/post/tidytuesday2019/week2/week-2-imdb-tv-shows-data/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week2/week-2-imdb-tv-shows-data/</guid>
      <description>GenreGenre and SeasonGenre and YearGenre and MonthSeasonSeason and YearSeason and MonthTop 3 GenresCrime Drama MysteryComedy DramaDramaRating over the yearsTv Series with more than 14 Seasons# loading the packageslibrary(tidyverse)library(summarytools)library(magrittr)library(readr)library(lubridate)library(gganimate)library(stringr)# load the datasetRatings &amp;lt;- read_csv(&amp;quot;IMDb_Economist_tv_ratings.csv&amp;quot;, col_types = cols(date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;)))Ratings data-set is from the IMDB site.</description>
    </item>
    
    <item>
      <title>2019 Week 1 : #TidyTuesday Tweets </title>
      <link>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</guid>
      <description>#Tidytuesday TweetsEarliest TweetAny Verified Profiles ?Source of TweetsTweets Per MonthMost Tweets By Screen NameMost Tweets By Screen Name and their SourceMost Tweets By Screen Name with their Retweet CountsMost Tweets By Screen Name with their Favorite CountsRelationship between Favorite Counts vs Retweet Counts ?Relationship between Followers Count vs Friends Count ?ConclusionFurther Analysis# load the necessary packageslibrary(tidyverse)library(lubridate)library(kableExtra)library(ggthemr)#load the ggthemrggthemr(&amp;quot;flat dark&amp;quot;)# load the data settidytuesday_tweets&amp;lt;-readRDS(&amp;quot;tidytuesday_tweets.</description>
    </item>
    
    <item>
      <title>Benchmarking the mle and mle2 function </title>
      <link>/post/mleand2/benchmarking-the-mle-and-mle2-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mleand2/benchmarking-the-mle-and-mle2-function/</guid>
      <description>Introductionmlemle2ConclusionNOTE : Below post is valid for Package version 1.4.0 and Before. 
Introductionmle and mle2are my favorite functions, because they provide extensive amount of outputsfor the optimization process. Even though there is no difference in analytical methodsused in both of these functions. Further, these analytical methods are the same ones usedby optim function. To be honest mle and mle2 functions are wrapper functions of optim.</description>
    </item>
    
    <item>
      <title>Build a New Package with Existing R packages</title>
      <link>/post/newpackage/build-a-new-package-with-existing-r-packages/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/newpackage/build-a-new-package-with-existing-r-packages/</guid>
      <description>IntroductionMost Essential Packagesdevtoolspkgbuildpkgloadrcmdcheckusethisroxygen2knitrmarkdown, rmarkdown, rmdformatsspellingtrackmdtestthatEssential Packagesgit2r and ghdesccovrbadgecreatr and badgerhexStickerpkgdownStill I have not UsedpackratpkgconfigpkginspectorrvcheckrversionsformatRwhoamiConclusionIntroductionPackage development is a sense of accomplishment for any statistical programmer who needs self satisfaction. I developed the R package fitODBOD for the purpose of fitting Over dispersed Binomial Outcome Data using Binomial Mixture Distributions and Alternate Binomial Distributions.</description>
    </item>
    
    <item>
      <title>How To Find Your R package ?</title>
      <link>/post/findrpackage/how-to-find-your-r-package/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/findrpackage/how-to-find-your-r-package/</guid>
      <description>1. Google2. CRAN3. Bio - Conductor4. GitHub pages5. Rdocumentation6. Crantastic7. rpackages8. R - Opensci9. Rseek10. R Site Search11. R-forge12. AwesomeR13. CRAN Task View14. Rstudio - Rpackages15. stack overflow - r16. CRANalertsHow to find your R package is simply a blog post helping people to provide a list of websites where they can find R packages.</description>
    </item>
    
    <item>
      <title>Benchmarking the maxLik function</title>
      <link>/post/maxlik/benchmarking-maxlik-function/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/maxlik/benchmarking-maxlik-function/</guid>
      <description>Estimating the shape parameters of Beta-Binomial DistributionIntroductionBrief of maxLik FunctionNR methodBFGS methodBFGSR methodBHHH methodSANN methodCG methodNM methodSumary of Time evalutation for different Analytical methods of maxLik functionSummary of results after using the maxLik function for different analytical methodsFinal ConclusionNOTE : Below post is valid for Package version 1.4.0 and Before. 
Estimating the shape parameters of Beta-Binomial DistributionIntroductionBeginning of this month I wrote asmall sectionregarding maxLik function by comparing it to other optimization functions.</description>
    </item>
    
    <item>
      <title>Week 38: Sea Creatures</title>
      <link>/post/week_38/week-38-sea-creatures/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_38/week-38-sea-creatures/</guid>
      <description>IOS slide PresentationIntroductionPackages UsedSpecies vs Sex vs BirthYear (code)Species vs Sex vs BirthYear (plot)Status vs Sex vs BirthYear (code)Status vs Sex vs BirthYear (plot)Species vs Sex vs Status (code)Species vs Sex vs Status (plot)Birth Year and Sex of the Acquisitioned (code)Birth Year and Sex of the Acquisitioned (plot)Species and their sex over current location (code)Species and their sex over current location (plot)Acquisitioned ones and thier Sex with Status (code)Acquisitioned ones and thier Sex with Status (plot)ConclusionOver the weeks I have only done blog posts for TidyTuesday.</description>
    </item>
    
    <item>
      <title>Benchmarking the optim function</title>
      <link>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</guid>
      <description>Estimating the shape parameters of Beta-Binomial DistributionIntroductionBrief of optim FunctionNelder and Mead methodBFGS methodCG methodL-BFGS-B methodSANN methodBrent methodSummary of Time evaluation for different Analytical methods of optim functionSummary of results after using the optim function for different analytical methodsFinal ConclusionNOTE : Below post is valid for Package version 1.4.0 and Before. 
Estimating the shape parameters of Beta-Binomial DistributionIntroductionI wrote a blog postearlier this month to understand the optimization functions in R and compare them.</description>
    </item>
    
    <item>
      <title>Week 37: NYC Restaurants</title>
      <link>/post/week_37/week-37-nyc-restaurants/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_37/week-37-nyc-restaurants/</guid>
      <description>Inspection TypeCritical FlagInspection Type and Critical Flag over the yearsCycle InspectionPre-permit OperationalAdministrative MiscellaneousMost Inspected RestaurantsDunkin DonutsSubwayMcDonaldsStarbucksKennedy Fried ChickenConclusionFurther Analysis# load the packageslibrary(readr)library(tidyverse)library(magrittr)library(ggthemr)library(lubridate)library(stringr)library(kableExtra)#using themeggthemr(&amp;quot;fresh&amp;quot;)#load dataNYC&amp;lt;-read_csv(&amp;quot;nyc_restaurants.csv&amp;quot;, col_types = cols(inspection_date = col_date(format = &amp;quot;%m/%d/%Y&amp;quot;)))attach(NYC)Data set is completed with more than 300000 records and several important variables such as inspection date, violation code, critical flag, score and violation description.</description>
    </item>
    
    <item>
      <title>Week 36: Medium Posts</title>
      <link>/post/week_36/week-36-medium-posts/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_36/week-36-medium-posts/</guid>
      <description>ClapsTop 10 Authors and Claps for their postsTop 10 Authors with most postsTop 10 Authors who have posts with ImagesTop 10 Authors who have posts without ImagesTop 10 Authors and Reading time for their postsTop 5 Publications with most postsWord Cloud for the Titles from Top 10 AuthorsWord Cloud for the Titles from Top 5 publicationsConclusionFurther Analysis#loading packages#load datalibrary(readr)#manipulate datalibrary(dplyr)library(magrittr)# format table with expenselibrary(formattable)# knitting the documentlibrary(knitr)# another type of tablelibrary(kableExtra)# playing with stringslibrary(stringr)# combining two plotslibrary(grid)library(gridExtra)# that theme you wantedlibrary(ggthemr)# text analysislibrary(tm)library(SnowballC)library(RColorBrewer)library(wordcloud)# adding theme called fresh for plotsggthemr(&amp;quot;fresh&amp;quot;)#loading the datamedium &amp;lt;- read_csv(&amp;quot;medium_datasci.</description>
    </item>
    
    <item>
      <title>Benchmarking optimization functions in R</title>
      <link>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</guid>
      <description>Estimating the shape parameters by Maximizing the Log Likelihood value of Beta-Binomial Distribution.Introductionoptim Functionnlm Functionnlminb Functionucminf FunctionmaxLik Functionmle Functionmle2 FunctionSummary of the seven optimization functions in RSummary of Time evaluation for the seven optimization R functionsSummary of Results after estimating parameters using the optimization R functionsFinal ConclusionNOTE : Below post is valid for Package version 1.</description>
    </item>
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description>Bridge Data and BaltimoreCounties which have bridges owned by State Highway AgencyCounties which have bridges owned by County Highway AgencyCounties which have bridges owned by State Toll AuthorityMost amount of bridges Built based on YearAverage Traffic Less than or equal to 100,000 for Counties with Bridge ConditionAverage Traffic More than 100,000 for Counties with Bridge ConditionImprovement and Bridge Conditions with CountiesConclusionFurther Analysis# loading the packageslibrary(readr)library(tidyverse)library(stringr)library(ggthemr)library(gganimate)library(formattable)# load the theme flat darkggthemr(&amp;quot;flat dark&amp;quot;)# reading the databridges &amp;lt;- read_csv(&amp;quot;baltimore_bridges.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description>People who do and do not celebrate ThanksgivingAge DistributionAge with Other FactorsGender DistributionGender with Other FactorsFamily Income DistributionFamily Income with Other FactorsUS Region DistributionConclusionFurther Analysis# Load the packgeslibrary(ggplot2)library(ggthemr)library(stringr)library(gridExtra)library(tidyverse)library(tweenr)library(gganimate)library(kableExtra)library(magrittr)library(knitr)library(readr)#load the dataThanksgiving&amp;lt;-read_csv(&amp;quot;thanksgiving_meals.csv&amp;quot;)# apply the theme grapeggthemr(&amp;quot;grape&amp;quot;)#subset the people who said yes for celebrating thanksgivingThanksgiving_Yes&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;Yes&amp;quot;)#subset the people who said no for celebrating thanksgivingThanksgiving_No&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;No&amp;quot;)Data set was provided on week 34 for TidyTuesday analysis.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description>What I posted in #TidyTuesday on 13th November 2018.SDI Countries with Malaria Death Count RateSaharan Region with Malaria Death Count RateEuropean Countries with Malaria Death Count RateGreat Britain or United Kingdom with Malaria Death Count RateAmerican Region with Malaria Death Count RateAsian Countries with Malaria Death Count RateNorth Africa and Middle East Region with Death Count RateOceania Region with Death Count RateCaribbean and Latin America and Caribbean Countries with Death Count RateConclusionFurther Analysis# load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description>IntroductionOperating SystemsR versionsDate versus Operating SystemDownload Size and IP IDConclusionFurther Analysis# load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))Week 31 : R and Package Downloads #TidyTuesday https://t.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitUnderstand Genre and Mpaa Rating on MoviesLets Focus of movies which has zero domestic grossZero Domestic gross Point of ViewGenre and MPAA Rating Point of ViewFinding Outliers in Perspective of Genre and MPAA RatingProduction Budget and Worldwide GrossYears, Months and Days versus Production BudgetConclusionFurther AnalysisMovie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set.</description>
    </item>
    
  </channel>
</rss>