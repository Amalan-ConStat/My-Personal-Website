<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Consulting Statistician</title>
    <link>/post/</link>
    <description>Recent content in Posts on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0530</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sri Lanka and its affect on/in Journal Articles </title>
      <link>/post/slandjournal/slandjournal/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/slandjournal/slandjournal/</guid>
      <description>IntroductionPackages and IdeasRanking of Sri Lanka from 1996 to 2017Documents , Citable Documents and Self Citations from Sri Lanka Journals from 1996 to 2017Citations per Document from Sri Lankan JournalsIntroductionPackages and Ideas# Datalibrary(sjrdata)# Packageslibrary(tidyverse)library(gganimate)library(ggrepel)library(magrittr)library(lubridate)library(ggthemr)ggthemr(&amp;quot;flat dark&amp;quot;)Ranking of Sri Lanka from 1996 to 2017subset(sjr_countries,country==&amp;quot;Sri Lanka&amp;quot;) %&amp;gt;%mutate(year=year(as.Date(year,&amp;quot;%Y&amp;quot;))) %&amp;gt;%ggplot(.,aes(x=year,y=rank,label=rank))+geom_point()+geom_line()+geom_text_repel()+xlab(&amp;quot;Year&amp;quot;)+ylab(&amp;quot;Rank&amp;quot;)+ggtitle(&amp;quot;Rank of Sri Lanka Changing from 1996 to 2017&amp;quot;)+theme(axis.</description>
    </item>
    
    <item>
      <title>Tree of Binomial Distribution</title>
      <link>/post/binomialdistribution/binomialdistribution/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/binomialdistribution/binomialdistribution/</guid>
      <description>Binomial DistributionApplicationsBinomial Mixture DistributionsMain Groups for Binomial DistributionOther With No Sub-GroupsGrassia Binomial DistributionZero Modified Binomial DistributionDandekar’s Modified Binomial DistributionSimplex Binomial Mixture ModelDouble Binomial DistributionFinite Biomial MixturesBinomial Distribution of order KTruncated Binomial DistributionWeighted Binomial DistributionBinomial Not ParentHypergeometric + BinomialNegative Binomial + BinomialPoisson + BinomialAlternate Binomial DistributionsAdditive Binomial DistributionBeta-Correlated Binomial DistributionCOM-Poisson Binomial DistributionCorrelated Binomial DistributionMultiplicative Binomial DistributionNeyman Type A DistributionPoisson + Binomial + BetaPoisson + Poisson + Binomial + Beta or Poisson + Binomial + Poisson + BetaHermite DistributionBinomial + PoissonPoisson + BinomialBinomial ParentN/n , K and Y Mixturesp Transformed BinomialLog Inverse Distribution [0,1] DomainCumulative Distribution Functionp BinomialReferencesBinomial DistributionThe binomial distribution can be defined, using the binomial expansion</description>
    </item>
    
    <item>
      <title>Week 7: Spending On Science Stuff</title>
      <link>/post/tidytuesday2019/week7/week7/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week7/week7/</guid>
      <description>Climate Change ResearchEnergyFederal# load the packages library(readr)library(tidyverse)library(gganimate)library(dplyr)library(magrittr)# load the dataclimate &amp;lt;- read_csv(&amp;quot;climate_spending.csv&amp;quot;)energy &amp;lt;- read_csv(&amp;quot;energy_spending.csv&amp;quot;, col_types = cols(year = col_integer()))federal &amp;lt;- read_csv(&amp;quot;fed_r_d_spending.csv&amp;quot;)Even though I can go further and do an investigative plotting from the rest data it is not done here. I was more focused on the scientific notation values in the plotting and scales, which were bothering me a lot.</description>
    </item>
    
    <item>
      <title>Week 6 : Mortgage, Recession and States</title>
      <link>/post/tidytuesday2019/week6/week6/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week6/week6/</guid>
      <description>MortgageFixed Rate 30 Years from 1971 to 2018Fixed Rate 15 Years from 1991 to 2018Fees and Points of 30 Years from 1971 to 2018Fees and Points of 15 Years from 1991 to 2018StatesNew England RegionMideast RegionGreat Lakes RegionPlains RegionSoutheast RegionSouthwest RegionRocky Mountain RegionFar West Region# load the packageslibrary(readr)library(tidyverse)library(bbplot)library(gganimate)library(magrittr)library(lubridate)# load the datamortgage &amp;lt;- read_csv(&amp;quot;mortgage.</description>
    </item>
    
    <item>
      <title>Week 5: Dairy Products in USA</title>
      <link>/post/tidytuesday2019/week5/week-5-dairy-products-in-usa/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week5/week-5-dairy-products-in-usa/</guid>
      <description>IntroductionFluid Milk SalesState Milk ProductionUS States and Milk Production Over the YearsSumming States of Same Regions Over the YearsAveraging Regions Considering All the States Over the YearsCheeseCheese with OtherCheese with TotalCheese with known Type Names# load the packageslibrary(tidyverse)library(magrittr)library(ggthemr)library(readr)library(gganimate)library(usmap)# load the datafluid_milk_sales &amp;lt;- read_csv(&amp;quot;fluid_milk_sales.csv&amp;quot;)state_milk_production &amp;lt;- read_csv(&amp;quot;state_milk_production.csv&amp;quot;)clean_cheese &amp;lt;- read_csv(&amp;quot;clean_cheese.</description>
    </item>
    
    <item>
      <title>Build Your Own Website or Blog Using R, RStudio and R Packages.</title>
      <link>/post/personalwebsite/build-your-own-website-or-blog-using-r-rstudio-and-r-packages/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/personalwebsite/build-your-own-website-or-blog-using-r-rstudio-and-r-packages/</guid>
      <description>IntroductionMaterials“Making Websites with Rmarkdown and Blogdown by Yihui Xie.”“Up and Running with Blogdown by Alison Presmanes Hill.”“Rmarkdown Websites.”“How to make an RMarkdown Website by Nick Strayer &amp;amp; Lucy D’Agostino McGowan.”“Creating websites in R by Emily C Zabor.”“Getting Started with Blogdown by David Selby.”“Getting Started with Blogdown by Danielle Navarro.”“Blogdown by Peter’s Blog.”“Academic by George Cushen”*“Happy Git and GitHub for the User.</description>
    </item>
    
    <item>
      <title>Olympic : Rshiny Approach</title>
      <link>/post/olympicrshiny/olympic-rshiny-approach/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/olympicrshiny/olympic-rshiny-approach/</guid>
      <description>IntroductionMaterial Useful for Rsiny DevelopmentHow To Use The Olympic Rshiny App ?Step 1Step 2Step 3Step 4Step 5Step 6Step 7Step 8IntroductionRshiny is very popular in the rstats community. The glamourous interface and functionality has helped for this level of popularity. In perspective of using an Rshiny App anyone can use it with minimal amount of knowledge.</description>
    </item>
    
    <item>
      <title>Week 4: Prison Data</title>
      <link>/post/tidytuesday2019/week4/week-4-prison-data/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week4/week-4-prison-data/</guid>
      <description>Prison SummaryPrison Summary With GenderPrison Summary with EthnicityPrison Summary with Other and TotalPretrial Summary with Gender and TotalComplete Data of Incarceration TrendsRape Crimes over the Years in States of Rural AreaRape Crimes over the Years in States of Small or Mid AreaRape Crimes over the Years in States of Suburban AreaRape Crimes over the Years in States of Urban Area# load the packageslibrary(readr)library(tidyverse)library(magrittr)library(gganimate)library(ggthemr)# load the themeggthemr(&amp;quot;flat dark&amp;quot;)# load the datapretrial_summary &amp;lt;- read_csv(&amp;quot;pretrial_summary.</description>
    </item>
    
    <item>
      <title>Week 3: Space Agencies and Launches</title>
      <link>/post/tidytuesday2019/week3/week-3-space-agencies-and-launches/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week3/week-3-space-agencies-and-launches/</guid>
      <description>AGENCIESAgency vs CountType vs CountClass vs CountAgency Type vs CountState Code vs CountLocation vs CountStart Year and End Year vs agencyLAUNCHESSuccess or Failure of these missions vs Category VariablesSuccess or Failure vs Launch YearSuccess or Failure vs Agency TypeSuccess or Failure vs State CodeState Code vs Category Over time for Success and Failurelibrary(readr)library(tidyverse)library(ggalt)library(magrittr)library(dplyr)library(ggthemr)library(gganimate)# Load the Agency dataagencies&amp;lt;-read_csv(&amp;quot;agencies.</description>
    </item>
    
    <item>
      <title>Developing an R package</title>
      <link>/post/yourownpackage/developing-an-r-package/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/yourownpackage/developing-an-r-package/</guid>
      <description>IntroductionCredit to People of R Community1) Coding Standards (Coding to Understand)2) Package Structure3) DESCRIPTION file4) README file5) /R directory6) /data directory7) /tests directory8) /man directory9) NAMSESPACE file10) .Rbuildignore file11) .gitignore fileBuilding the PackageDistributing the PackageIntroductionR package development is no longer as it was before 2010 because now most of the work can be done by just a simple mouse-click or with the use of a function.</description>
    </item>
    
    <item>
      <title>Week 2: IMDB TV Shows Data</title>
      <link>/post/tidytuesday2019/week2/week-2-imdb-tv-shows-data/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week2/week-2-imdb-tv-shows-data/</guid>
      <description>GenreGenre and SeasonGenre and YearGenre and MonthSeasonSeason and YearSeason and MonthTop 3 GenresCrime Drama MysteryComedy DramaDramaRating over the yearsTv Series with more than 14 Seasons# loading the packageslibrary(tidyverse)library(summarytools)library(magrittr)library(readr)library(lubridate)library(gganimate)library(stringr)# load the datasetRatings &amp;lt;- read_csv(&amp;quot;IMDb_Economist_tv_ratings.csv&amp;quot;, col_types = cols(date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;)))Ratings data-set is from the IMDB site.</description>
    </item>
    
    <item>
      <title>2019 Week 1 : #TidyTuesday Tweets </title>
      <link>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</guid>
      <description>#Tidytuesday TweetsEarliest TweetAny Verified Profiles ?Source of TweetsTweets Per MonthMost Tweets By Screen NameMost Tweets By Screen Name and their SourceMost Tweets By Screen Name with their Retweet CountsMost Tweets By Screen Name with their Favorite CountsRelationship between Favorite Counts vs Retweet Counts ?Relationship between Followers Count vs Friends Count ?ConclusionFurther Analysis# load the necessary packageslibrary(tidyverse)library(lubridate)library(kableExtra)library(ggthemr)#load the ggthemrggthemr(&amp;quot;flat dark&amp;quot;)# load the data settidytuesday_tweets&amp;lt;-readRDS(&amp;quot;tidytuesday_tweets.</description>
    </item>
    
    <item>
      <title>Benchmarking the mle and mle2 function </title>
      <link>/post/mleand2/benchmarking-the-mle-and-mle2-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mleand2/benchmarking-the-mle-and-mle2-function/</guid>
      <description>Introductionmlemle2ConclusionIntroductionmle and mle2 are my favorite functions, because they provide extensive amount of outputs for the optimization process. Even though there is no difference in analytical methods used in both of these functions. Further, these analytical methods are the same ones used by optim function. To be honest mle and mle2 functions are wrapper functions of optim. It means both mle and mle2 are using the optim function inside but with some additional inputs, which would generate extended outputs.</description>
    </item>
    
    <item>
      <title>Build a New Package with Existing R packages</title>
      <link>/post/newpackage/build-a-new-package-with-existing-r-packages/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/newpackage/build-a-new-package-with-existing-r-packages/</guid>
      <description>IntroductionMost Essential Packagesdevtoolspkgbuildpkgloadrcmdcheckusethisroxygen2knitrmarkdown, rmarkdown, rmdformatsspellingtrackmdtestthatEssential Packagesgit2r and ghdesccovrbadgecreatr and badgerhexStickerpkgdownStill I have not UsedpackratpkgconfigpkginspectorrvcheckrversionsformatRwhoamiConclusionIntroductionPackage development is a sense of accomplishment for any statistical programmer who needs self satisfaction. I developed the R package fitODBOD for the purpose of fitting Over dispersed Binomial Outcome Data using Binomial Mixture Distributions and Alternate Binomial Distributions.</description>
    </item>
    
    <item>
      <title>How To Find Your R package ?</title>
      <link>/post/findrpackage/how-to-find-your-r-package/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/findrpackage/how-to-find-your-r-package/</guid>
      <description>1. Google2. CRAN3. Bio - Conductor4. GitHub pages5. Rdocumentation6. Crantastic7. rpackages8. R - Opensci9. Rseek10. R Site Search11. R-forge12. AwesomeR13. CRAN Task View14. Rstudio - Rpackages15. stack overflow - r16. CRANalertsHow to find your R package is simply a blog post helping people to provide a list of websites where they can find R packages.</description>
    </item>
    
    <item>
      <title>Benchmarking the maxLik function</title>
      <link>/post/maxlik/benchmarking-maxlik-function/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/maxlik/benchmarking-maxlik-function/</guid>
      <description>Estimating the shape parameters of Beta-Binomial DistributionIntroductionBrief of maxLik FunctionNR methodBFGS methodBFGSR methodBHHH methodSANN methodCG methodNM methodSumary of Time evalutation for different Analytical methods of maxLik functionSummary of results after using the maxLik function for different analytical methodsFinal ConclusionEstimating the shape parameters of Beta-Binomial DistributionIntroductionBeginning of this month I wrote a small section regarding maxLik function by comparing it to other optimization functions.</description>
    </item>
    
    <item>
      <title>Week 38: Sea Creatures</title>
      <link>/post/week_38/week-38-sea-creatures/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_38/week-38-sea-creatures/</guid>
      <description>IOS slide PresentationIntroductionPackages UsedSpecies vs Sex vs BirthYear (code)Species vs Sex vs BirthYear (plot)Status vs Sex vs BirthYear (code)Status vs Sex vs BirthYear (plot)Species vs Sex vs Status (code)Species vs Sex vs Status (plot)Birth Year and Sex of the Acquisitioned (code)Birth Year and Sex of the Acquisitioned (plot)Species and their sex over current location (code)Species and their sex over current location (plot)Acquisitioned ones and thier Sex with Status (code)Acquisitioned ones and thier Sex with Status (plot)ConclusionOver the weeks I have only done blog posts for TidyTuesday.</description>
    </item>
    
    <item>
      <title>Benchmarking the optim function</title>
      <link>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</guid>
      <description>Estimating the shape parameters of Beta-Binomial DistributionIntroductionBrief of optim FunctionNelder and Mead methodBFGS methodCG methodL-BFGS-B methodSANN methodBrent methodSummary of Time evaluation for different Analytical methods of optim functionSummary of results after using the optim function for different analytical methodsFinal ConclusionEstimating the shape parameters of Beta-Binomial DistributionIntroductionI wrote a blog post earlier this month to understand the optimization functions in R and compare them.</description>
    </item>
    
    <item>
      <title>Week 37: NYC Restaurants</title>
      <link>/post/week_37/week-37-nyc-restaurants/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_37/week-37-nyc-restaurants/</guid>
      <description>Inspection TypeCritical FlagInspection Type and Critical Flag over the yearsCycle InspectionPre-permit OperationalAdministrative MiscellaneousMost Inspected RestaurantsDunkin DonutsSubwayMcDonaldsStarbucksKennedy Fried ChickenConclusionFurther Analysis# load the packageslibrary(readr)library(tidyverse)library(magrittr)library(ggthemr)library(lubridate)library(stringr)library(kableExtra)#using themeggthemr(&amp;quot;fresh&amp;quot;)#load dataNYC&amp;lt;-read_csv(&amp;quot;nyc_restaurants.csv&amp;quot;, col_types = cols(inspection_date = col_date(format = &amp;quot;%m/%d/%Y&amp;quot;)))attach(NYC)Data set is completed with more than 300000 records and several important variables such as inspection date, violation code, critical flag, score and violation description.</description>
    </item>
    
    <item>
      <title>Week 36: Medium Posts</title>
      <link>/post/week_36/week-36-medium-posts/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_36/week-36-medium-posts/</guid>
      <description>ClapsTop 10 Authors and Claps for their postsTop 10 Authors with most postsTop 10 Authors who have posts with ImagesTop 10 Authors who have posts without ImagesTop 10 Authors and Reading time for their postsTop 5 Publications with most postsWord Cloud for the Titles from Top 10 AuthorsWord Cloud for the Titles from Top 5 publicationsConclusionFurther Analysis#loading packages#load datalibrary(readr)#manipulate datalibrary(dplyr)library(magrittr)# format table with expenselibrary(formattable)# knitting the documentlibrary(knitr)# another type of tablelibrary(kableExtra)# playing with stringslibrary(stringr)# combining two plotslibrary(grid)library(gridExtra)# that theme you wantedlibrary(ggthemr)# text analysislibrary(tm)library(SnowballC)library(RColorBrewer)library(wordcloud)# adding theme called fresh for plotsggthemr(&amp;quot;fresh&amp;quot;)#loading the datamedium &amp;lt;- read_csv(&amp;quot;medium_datasci.</description>
    </item>
    
    <item>
      <title>Benchmarking optimization functions in R</title>
      <link>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</guid>
      <description>Estimating the shape parameters by Maximizing the Log Likelihood value of Beta-Binomial Distribution.Introductionoptim Functionnlm Functionnlminb Functionucminf FunctionmaxLik Functionmle Functionmle2 FunctionSummary of the seven optimization functions in RSummary of Time evaluation for the seven optimization R functionsSummary of Results after estimating parameters using the optimization R functionsFinal ConclusionEstimating the shape parameters by Maximizing the Log Likelihood value of Beta-Binomial Distribution.</description>
    </item>
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description>Bridge Data and BaltimoreCounties which have bridges owned by State Highway AgencyCounties which have bridges owned by County Highway AgencyCounties which have bridges owned by State Toll AuthorityMost amount of bridges Built based on YearAverage Traffic Less than or equal to 100,000 for Counties with Bridge ConditionAverage Traffic More than 100,000 for Counties with Bridge ConditionImprovement and Bridge Conditions with CountiesConclusionFurther Analysis# loading the packageslibrary(readr)library(tidyverse)library(stringr)library(ggthemr)library(gganimate)library(formattable)# load the theme flat darkggthemr(&amp;quot;flat dark&amp;quot;)# reading the databridges &amp;lt;- read_csv(&amp;quot;baltimore_bridges.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description>People who do and do not celebrate ThanksgivingAge DistributionAge with Other FactorsGender DistributionGender with Other FactorsFamily Income DistributionFamily Income with Other FactorsUS Region DistributionConclusionFurther Analysis# Load the packgeslibrary(ggplot2)library(ggthemr)library(stringr)library(gridExtra)library(tidyverse)library(tweenr)library(gganimate)library(kableExtra)library(magrittr)library(knitr)library(readr)#load the dataThanksgiving&amp;lt;-read_csv(&amp;quot;thanksgiving_meals.csv&amp;quot;)# apply the theme grapeggthemr(&amp;quot;grape&amp;quot;)#subset the people who said yes for celebrating thanksgivingThanksgiving_Yes&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;Yes&amp;quot;)#subset the people who said no for celebrating thanksgivingThanksgiving_No&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;No&amp;quot;)Data set was provided on week 34 for TidyTuesday analysis.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description>What I posted in #TidyTuesday on 13th November 2018.SDI Countries with Malaria Death Count RateSaharan Region with Malaria Death Count RateEuropean Countries with Malaria Death Count RateGreat Britain or United Kingdom with Malaria Death Count RateAmerican Region with Malaria Death Count RateAsian Countries with Malaria Death Count RateNorth Africa and Middle East Region with Death Count RateOceania Region with Death Count RateCaribbean and Latin America and Caribbean Countries with Death Count RateConclusionFurther Analysis# load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description>IntroductionOperating SystemsR versionsDate versus Operating SystemDownload Size and IP IDConclusionFurther Analysis# load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))Week 31 : R and Package Downloads #TidyTuesday https://t.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitUnderstand Genre and Mpaa Rating on MoviesLets Focus of movies which has zero domestic grossZero Domestic gross Point of ViewGenre and MPAA Rating Point of ViewFinding Outliers in Perspective of Genre and MPAA RatingProduction Budget and Worldwide GrossYears, Months and Days versus Production BudgetConclusionFurther AnalysisMovie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set.</description>
    </item>
    
  </channel>
</rss>