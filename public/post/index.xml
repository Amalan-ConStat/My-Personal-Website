<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Consulting Statistician</title>
    <link>/post/</link>
    <description>Recent content in Posts on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0530</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Week 36: Medium Posts</title>
      <link>/post/week_36/week-36-medium-posts/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_36/week-36-medium-posts/</guid>
      <description>#loading packages#load datalibrary(readr)#manipulate datalibrary(dplyr)library(magrittr)# format table with expenselibrary(formattable)# knitting the documentlibrary(knitr)# another type of tablelibrary(kableExtra)# playing with stringslibrary(stringr)# combining two plotslibrary(grid)library(gridExtra)# that theme you wantedlibrary(ggthemr)# text analysislibrary(tm)library(SnowballC)library(RColorBrewer)library(wordcloud)# adding theme called fresh for plotsggthemr(&amp;quot;fresh&amp;quot;)#loading the datamedium &amp;lt;- read_csv(&amp;quot;medium_datasci.csv&amp;quot;)attach(medium)Focusing on Claps with Authors and publications, where does writing alot of posts will get you popularity and claps.</description>
    </item>
    
    <item>
      <title>Benchmarking Maximum Likelihood Estimation functions from R</title>
      <link>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</link>
      <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/fitodbod_1/benchmarking-maximum-liklihood-functions-from-r/</guid>
      <description>IntroductionWhen we need to estimate parameters from a discrete distribution or continuous distribution or a function we can use the below mentioned R functions. We will be using the technique of maximizing the Log Likelihood function or minimizing the Negative Log Likelihood function. Based on this technique we will compare these R functions because it might benefit people who are struggling to which one to choose. We have 7 functions in total by my knowledge when I was writing this post.</description>
    </item>
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description># loading the packageslibrary(readr)library(tidyverse)library(stringr)library(ggthemr)library(gganimate)library(formattable)# load the theme flat darkggthemr(&amp;quot;flat dark&amp;quot;)# reading the databridges &amp;lt;- read_csv(&amp;quot;baltimore_bridges.csv&amp;quot;)#View(bridges)# naming the columnsnames(bridges)&amp;lt;-c(&amp;quot;lat&amp;quot;,&amp;quot;long&amp;quot;,&amp;quot;County&amp;quot;,&amp;quot;Carries&amp;quot;,&amp;quot;Year Built&amp;quot;,&amp;quot;Condition&amp;quot;,&amp;quot;Average Daily Traffic&amp;quot;,&amp;quot;Total Improvement&amp;quot;,&amp;quot;Month&amp;quot;,&amp;quot;Year&amp;quot;,&amp;quot;Owner&amp;quot;,&amp;quot;Responsibility&amp;quot;,&amp;quot;Vehicles&amp;quot;)attach(bridges)Bridge Data and BaltimoreData for the analysis and description about the Baltimore bridges are hyper-linked. Further , my tweet is also in this hyperlink.
Data on bridges is of week 35 from TidyTuesday.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description># Load the packgeslibrary(ggplot2)library(ggthemr)library(stringr)library(gridExtra)library(tidyverse)library(tweenr)library(gganimate)library(kableExtra)library(magrittr)library(knitr)library(readr)#load the dataThanksgiving&amp;lt;-read_csv(&amp;quot;thanksgiving_meals.csv&amp;quot;)# apply the theme grapeggthemr(&amp;quot;grape&amp;quot;)#subset the people who said yes for celebrating thanksgivingThanksgiving_Yes&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;Yes&amp;quot;)#subset the people who said no for celebrating thanksgivingThanksgiving_No&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;No&amp;quot;)Data set was provided on week 34 for TidyTuesday analysis. As it is Thanksgiving week this is understandable. You can receive the data set here.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description># load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.csv&amp;quot;)malaria_deaths_age&amp;lt;-read_csv(&amp;quot;malaria_deaths_age.csv&amp;quot;)attach(malaria_deaths)attach(malaria_deaths_age)# disseminating dataMalaria_deaths_Code_missing&amp;lt;-malaria_deaths[!complete.cases(Code),]MD_CM_SDI&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;High-middle SDI&amp;quot; | Entity == &amp;quot;High SDI&amp;quot; | Entity == &amp;quot;Low SDI&amp;quot; | Entity ==&amp;quot;Low-middle SDI&amp;quot; | Entity ==&amp;quot;Middle SDI&amp;quot;)MD_CM_Sahara&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Central Sub-Saharan Africa&amp;quot; |Entity == &amp;quot;Western Sub-Saharan Africa&amp;quot; | Entity == &amp;quot;Southern Sub-Saharan Africa&amp;quot; |Entity ==&amp;quot;Eastern Sub-Saharan Africa&amp;quot; | Entity ==&amp;quot;Sub-Saharan Africa&amp;quot;)MD_CM_EU&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Western Europe&amp;quot; | Entity == &amp;quot;Eastern Europe&amp;quot; | Entity == &amp;quot;Central Europe&amp;quot;)MD_CM_GB&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;England&amp;quot; | Entity == &amp;quot;Northern Ireland&amp;quot; | Entity == &amp;quot;Scotland&amp;quot; | Entity ==&amp;quot;Wales&amp;quot;)MD_CM_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Andean Latin America&amp;quot; | Entity == &amp;quot;North America&amp;quot; | Entity == &amp;quot;Southern Latin America&amp;quot; | Entity ==&amp;quot;Tropical Latin America&amp;quot; | Entity ==&amp;quot;Central Latin America&amp;quot; )MD_CM_A&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;North Africa and Middle East&amp;quot; | Entity == &amp;quot;Southeast Asia&amp;quot; | Entity == &amp;quot;Australasia&amp;quot; | Entity ==&amp;quot;East Asia&amp;quot; | Entity ==&amp;quot;Central Asia&amp;quot; | Entity ==&amp;quot;Oceania&amp;quot;| Entity ==&amp;quot;High-income Asia Pacific&amp;quot;| Entity ==&amp;quot;South Asia&amp;quot; )MD_CM_C_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Caribbean&amp;quot; | Entity == &amp;quot;Latin America and Caribbean&amp;quot;)# disseminating data#Malaria_deaths_age_Code_missing&amp;lt;-malaria_deaths_age[!</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description># load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))IntroductionTidy Tuesday is a very good move to improve R programming for anyone who is interested in statistics.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set. Even though the title of data says Movie profit I am going to focus on the movies which did not generate any revenue domestic and suggest on gross in worldwide.
The packages that I have used here are magrittr, tidyverse, scales, ggthemr, knitr, kableExtra, ggthemr and lubridate. The theme I am using for plots is “flat dark”.</description>
    </item>
    
  </channel>
</rss>