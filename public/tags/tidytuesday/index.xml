<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TidyTuesday on Consulting Statistician</title>
    <link>/tags/tidytuesday/</link>
    <description>Recent content in TidyTuesday on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 28 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/tidytuesday/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description>Bridge Data and BaltimoreData for the analysis and description about the Baltimore bridges are hyper-linked. Further , my tweet is also in this hyperlink.
Data on bridges is of week 35 from TidyTuesday. Trying to explain the data using maps is obvious, yet I will use animated jitter plots. There are 13 variables and 2079 observations. Brave choice of limiting my self to less than 10 variables, where latitude, longitude and Vehicles will not be taken into account.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description>Data set was provided on week 34 for TidyTuesday analysis. As it is Thanksgiving week this is understandable. You can receive the data set here. There are more than 65 variables and 1058 observations. The data was acquired buy a survey conducted online and information about them are here.
This is my tweet on week 34
People who do and do not celebrate ThanksgivingIn this ThanksGiving data set 980 are celebrating, and 78 are not celebrating Thanksgiving.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description># load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.csv&amp;quot;)malaria_deaths_age&amp;lt;-read_csv(&amp;quot;malaria_deaths_age.csv&amp;quot;)attach(malaria_deaths)attach(malaria_deaths_age)# disseminating dataMalaria_deaths_Code_missing&amp;lt;-malaria_deaths[!complete.cases(Code),]MD_CM_SDI&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;High-middle SDI&amp;quot; | Entity == &amp;quot;High SDI&amp;quot; | Entity == &amp;quot;Low SDI&amp;quot; | Entity ==&amp;quot;Low-middle SDI&amp;quot; | Entity ==&amp;quot;Middle SDI&amp;quot;)MD_CM_Sahara&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Central Sub-Saharan Africa&amp;quot; |Entity == &amp;quot;Western Sub-Saharan Africa&amp;quot; | Entity == &amp;quot;Southern Sub-Saharan Africa&amp;quot; |Entity ==&amp;quot;Eastern Sub-Saharan Africa&amp;quot; | Entity ==&amp;quot;Sub-Saharan Africa&amp;quot;)MD_CM_EU&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Western Europe&amp;quot; | Entity == &amp;quot;Eastern Europe&amp;quot; | Entity == &amp;quot;Central Europe&amp;quot;)MD_CM_GB&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;England&amp;quot; | Entity == &amp;quot;Northern Ireland&amp;quot; | Entity == &amp;quot;Scotland&amp;quot; | Entity ==&amp;quot;Wales&amp;quot;)MD_CM_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Andean Latin America&amp;quot; | Entity == &amp;quot;North America&amp;quot; | Entity == &amp;quot;Southern Latin America&amp;quot; | Entity ==&amp;quot;Tropical Latin America&amp;quot; | Entity ==&amp;quot;Central Latin America&amp;quot; )MD_CM_A&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;North Africa and Middle East&amp;quot; | Entity == &amp;quot;Southeast Asia&amp;quot; | Entity == &amp;quot;Australasia&amp;quot; | Entity ==&amp;quot;East Asia&amp;quot; | Entity ==&amp;quot;Central Asia&amp;quot; | Entity ==&amp;quot;Oceania&amp;quot;| Entity ==&amp;quot;High-income Asia Pacific&amp;quot;| Entity ==&amp;quot;South Asia&amp;quot; )MD_CM_C_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Caribbean&amp;quot; | Entity == &amp;quot;Latin America and Caribbean&amp;quot;)# disseminating data#Malaria_deaths_age_Code_missing&amp;lt;-malaria_deaths_age[!</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description># load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))IntroductionTidy Tuesday is a very good move to improve R programming for anyone who is interested in statistics.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set. Even though the title of data says Movie profit I am going to focus on the movies which did not generate any revenue domestic and suggest on gross in worldwide.
The packages that I have used here are magrittr, tidyverse, scales, ggthemr, knitr, kableExtra, ggthemr and lubridate. The theme I am using for plots is “flat dark”.</description>
    </item>
    
  </channel>
</rss>