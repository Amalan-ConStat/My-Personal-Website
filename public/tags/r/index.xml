<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Consulting Statistician</title>
    <link>/tags/r/</link>
    <description>Recent content in R on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Fri, 14 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>optim: Estimating the shape parameters of Beta-Binomial Distribution</title>
      <link>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</guid>
      <description>In the package fitODBOD we have the function EstMLEBetaBin which is constructed based on the Negative Log Likelihood function of Beta-Binomial distribution and we will use it. The optim function uses specific mathematical methods to find the most appropriate shape parameter values.
They are given below in point form 1. Nelder Mead 2. BFGS 3. CG 4. L-BFGS-B 5. SANN 6. Brent
Alcohol Consumption data has two sets of frequency values but only values from week 1 will be used.</description>
    </item>
    
    <item>
      <title>Week 37: NYC Restaurants</title>
      <link>/post/week_37/week-37-nyc-restaurants/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_37/week-37-nyc-restaurants/</guid>
      <description># load the packageslibrary(readr)library(tidyverse)library(magrittr)library(ggthemr)library(lubridate)library(stringr)library(kableExtra)#using themeggthemr(&amp;quot;fresh&amp;quot;)#load dataNYC&amp;lt;-read_csv(&amp;quot;nyc_restaurants.csv&amp;quot;, col_types = cols(inspection_date = col_date(format = &amp;quot;%m/%d/%Y&amp;quot;)))attach(NYC)Data set is completed with more than 300000 records and several important variables such as inspection date, violation code, critical flag, score and violation description. In this article I will mainly focus on Inspection Type, boro, Inspection year, cuisine type and Critical Flag.
That tweet.</description>
    </item>
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description># loading the packageslibrary(readr)library(tidyverse)library(stringr)library(ggthemr)library(gganimate)library(formattable)# load the theme flat darkggthemr(&amp;quot;flat dark&amp;quot;)# reading the databridges &amp;lt;- read_csv(&amp;quot;baltimore_bridges.csv&amp;quot;)#View(bridges)# naming the columnsnames(bridges)&amp;lt;-c(&amp;quot;lat&amp;quot;,&amp;quot;long&amp;quot;,&amp;quot;County&amp;quot;,&amp;quot;Carries&amp;quot;,&amp;quot;Year Built&amp;quot;,&amp;quot;Condition&amp;quot;,&amp;quot;Average Daily Traffic&amp;quot;,&amp;quot;Total Improvement&amp;quot;,&amp;quot;Month&amp;quot;,&amp;quot;Year&amp;quot;,&amp;quot;Owner&amp;quot;,&amp;quot;Responsibility&amp;quot;,&amp;quot;Vehicles&amp;quot;)attach(bridges)Bridge Data and BaltimoreData for the analysis and description about the Baltimore bridges are hyper-linked. Further , my tweet is also in this hyperlink.
Data on bridges is of week 35 from TidyTuesday.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description># Load the packgeslibrary(ggplot2)library(ggthemr)library(stringr)library(gridExtra)library(tidyverse)library(tweenr)library(gganimate)library(kableExtra)library(magrittr)library(knitr)library(readr)#load the dataThanksgiving&amp;lt;-read_csv(&amp;quot;thanksgiving_meals.csv&amp;quot;)# apply the theme grapeggthemr(&amp;quot;grape&amp;quot;)#subset the people who said yes for celebrating thanksgivingThanksgiving_Yes&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;Yes&amp;quot;)#subset the people who said no for celebrating thanksgivingThanksgiving_No&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;No&amp;quot;)Data set was provided on week 34 for TidyTuesday analysis. As it is Thanksgiving week this is understandable. You can receive the data set here.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description># load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.csv&amp;quot;)malaria_deaths_age&amp;lt;-read_csv(&amp;quot;malaria_deaths_age.csv&amp;quot;)attach(malaria_deaths)attach(malaria_deaths_age)# disseminating dataMalaria_deaths_Code_missing&amp;lt;-malaria_deaths[!complete.cases(Code),]MD_CM_SDI&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;High-middle SDI&amp;quot; | Entity == &amp;quot;High SDI&amp;quot; | Entity == &amp;quot;Low SDI&amp;quot; | Entity ==&amp;quot;Low-middle SDI&amp;quot; | Entity ==&amp;quot;Middle SDI&amp;quot;)MD_CM_Sahara&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Central Sub-Saharan Africa&amp;quot; |Entity == &amp;quot;Western Sub-Saharan Africa&amp;quot; | Entity == &amp;quot;Southern Sub-Saharan Africa&amp;quot; |Entity ==&amp;quot;Eastern Sub-Saharan Africa&amp;quot; | Entity ==&amp;quot;Sub-Saharan Africa&amp;quot;)MD_CM_EU&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Western Europe&amp;quot; | Entity == &amp;quot;Eastern Europe&amp;quot; | Entity == &amp;quot;Central Europe&amp;quot;)MD_CM_GB&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;England&amp;quot; | Entity == &amp;quot;Northern Ireland&amp;quot; | Entity == &amp;quot;Scotland&amp;quot; | Entity ==&amp;quot;Wales&amp;quot;)MD_CM_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Andean Latin America&amp;quot; | Entity == &amp;quot;North America&amp;quot; | Entity == &amp;quot;Southern Latin America&amp;quot; | Entity ==&amp;quot;Tropical Latin America&amp;quot; | Entity ==&amp;quot;Central Latin America&amp;quot; )MD_CM_A&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;North Africa and Middle East&amp;quot; | Entity == &amp;quot;Southeast Asia&amp;quot; | Entity == &amp;quot;Australasia&amp;quot; | Entity ==&amp;quot;East Asia&amp;quot; | Entity ==&amp;quot;Central Asia&amp;quot; | Entity ==&amp;quot;Oceania&amp;quot;| Entity ==&amp;quot;High-income Asia Pacific&amp;quot;| Entity ==&amp;quot;South Asia&amp;quot; )MD_CM_C_LA&amp;lt;-subset(Malaria_deaths_Code_missing,Entity == &amp;quot;Caribbean&amp;quot; | Entity == &amp;quot;Latin America and Caribbean&amp;quot;)# disseminating data#Malaria_deaths_age_Code_missing&amp;lt;-malaria_deaths_age[!</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description># load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))IntroductionTidy Tuesday is a very good move to improve R programming for anyone who is interested in statistics.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set. Even though the title of data says Movie profit I am going to focus on the movies which did not generate any revenue domestic and suggest on gross in worldwide.
The packages that I have used here are magrittr, tidyverse, scales, ggthemr, knitr, kableExtra, ggthemr and lubridate. The theme I am using for plots is “flat dark”.</description>
    </item>
    
    <item>
      <title>Website-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-website/</link>
      <pubDate>Sun, 30 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-website/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GitHub-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-github/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-github/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CRAN-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-cran/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-cran/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R Package Development to Model Over Dispersed Binomial Outcome Data with the use of Binomial Mixture Distributions and Alternate Binomial Distributions.</title>
      <link>/publication/4th-year/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/4th-year/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>