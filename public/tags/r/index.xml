<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Consulting Statistician</title>
    <link>/tags/r/</link>
    <description>Recent content in R on Consulting Statistician</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Week 1 : #TidyTuesday tweets </title>
      <link>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday2019/week1/week-1-tidytuesday-tweets/</guid>
      <description>#Tidytuesday TweetsEarliest TweetAny Verified Profiles ?Source of TweetsTweets Per MonthMost Tweets By Screen NameMost Tweets By Screen Name and their SourceMost Tweets By Screen Name with their Retweet CountsMost Tweets By Screen Name with their Favorite CountsRelationship between Favorite Counts vs Retweet Counts ?Relationship between Followers Count vs Friends Count ?ConclusionFurther Analysis# load the necessary packageslibrary(tidyverse)library(lubridate)library(kableExtra)library(ggthemr)#load the ggthemrggthemr(&amp;quot;flat dark&amp;quot;)# load the data settidytuesday_tweets&amp;lt;-readRDS(&amp;quot;tidytuesday_tweets.</description>
    </item>
    
    <item>
      <title>Benchmarking the mle and mle2 function </title>
      <link>/post/mleand2/benchmarking-the-mle-and-mle2-function/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mleand2/benchmarking-the-mle-and-mle2-function/</guid>
      <description>Introductionmlemle2ConclusionIntroductionmle and mle2 are my favorite functions, because they provide extensive amount of outputs for the optimization process. Even though there is no difference in analytical methods used in both of these functions. Further, these analytical methods are the same ones used by optim function. To be honest mle and mle2 functions are wrapper functions of optim. It means both mle and mle2 are using the optim function inside but with some additional inputs, which would generate extended outputs.</description>
    </item>
    
    <item>
      <title>Build a New Package with Existing R packages</title>
      <link>/post/newpackage/build-a-new-package-with-existing-r-packages/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/newpackage/build-a-new-package-with-existing-r-packages/</guid>
      <description>IntroductionMost Essential Packagesdevtoolspkgbuildpkgloadrcmdcheckusethisroxygen2knitrmarkdown, rmarkdown, rmdformatsspellingtrackmdtestthatEssential Packagesgit2r and ghdesccovrbadgecreatr and badgerhexStickerpkgdownStill I have not UsedpackratpkgconfigpkginspectorrvcheckrversionsformatRwhoamiConclusionIntroductionPackage development is a sense of accomplishment for any statistical programmer who needs self satisfaction. I developed the R package fitODBOD for the purpose of fitting Over dispersed Binomial Outcome Data using Binomial Mixture Distributions and Alternate Binomial Distributions.</description>
    </item>
    
    <item>
      <title>How To Find Your R package ?</title>
      <link>/post/findrpackage/how-to-find-your-r-package/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/findrpackage/how-to-find-your-r-package/</guid>
      <description>1. Google2. CRAN3. Bio - Conductor4. GitHub pages5. Rdocumentation6. Crantastic7. rpackages8. R - Opensci9. Rseek10. R Site Search11. R-forge12. AwesomeR13. CRAN Task View14. Rstudio - Rpackages15. stack overflow - r16. CRANalertsHow to find your R package is simply a blog post helping people to provide a list of websites where they can find R packages.</description>
    </item>
    
    <item>
      <title>Week 38: Sea Creatures</title>
      <link>/post/week_38/week-38-sea-creatures/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_38/week-38-sea-creatures/</guid>
      <description>IOS slide PresentationIntroductionPackages UsedSpecies vs Sex vs BirthYear (code)Species vs Sex vs BirthYear (plot)Status vs Sex vs BirthYear (code)Status vs Sex vs BirthYear (plot)Species vs Sex vs Status (code)Species vs Sex vs Status (plot)Birth Year and Sex of the Acquisitioned (code)Birth Year and Sex of the Acquisitioned (plot)Species and their sex over current location (code)Species and their sex over current location (plot)Acquisitioned ones and thier Sex with Status (code)Acquisitioned ones and thier Sex with Status (plot)ConclusionTHANK YOUOver the weeks I have only done blog posts for TidyTuesday.</description>
    </item>
    
    <item>
      <title>Benchmarking the optim function</title>
      <link>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/optim/optim-estimating-the-shape-parameters-of-beta-binomial-distribution/</guid>
      <description>Estimating the shape parameters of Beta-Binomial DistributionIntroductionBrief of optim FunctionNelder and Mead methodBFGS methodCG methodL-BFGS-B methodSANN methodBrent methodSummary of Time evaluation for different Analytical methods of optim functionSummary of results after using the optim function for different analytical methodsFinal ConclusionEstimating the shape parameters of Beta-Binomial DistributionIntroductionI wrote a blog post earlier this month to understand the optimization functions in R and compare them.</description>
    </item>
    
    <item>
      <title>Week 37: NYC Restaurants</title>
      <link>/post/week_37/week-37-nyc-restaurants/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_37/week-37-nyc-restaurants/</guid>
      <description>Inspection TypeCritical FlagInspection Type and Critical Flag over the yearsCycle InspectionPre-permit OperationalAdministrative MiscellaneousMost Inspected RestaurantsDunkin DonutsSubwayMcDonaldsStarbucksKennedy Fried ChickenConclusionFurther Analysis# load the packageslibrary(readr)library(tidyverse)library(magrittr)library(ggthemr)library(lubridate)library(stringr)library(kableExtra)#using themeggthemr(&amp;quot;fresh&amp;quot;)#load dataNYC&amp;lt;-read_csv(&amp;quot;nyc_restaurants.csv&amp;quot;, col_types = cols(inspection_date = col_date(format = &amp;quot;%m/%d/%Y&amp;quot;)))attach(NYC)Data set is completed with more than 300000 records and several important variables such as inspection date, violation code, critical flag, score and violation description.</description>
    </item>
    
    <item>
      <title>Week 35: Baltimore Bridges</title>
      <link>/post/week_35/week-35-baltimore-bridges/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_35/week-35-baltimore-bridges/</guid>
      <description>Bridge Data and BaltimoreCounties which have bridges owned by State Highway AgencyCounties which have bridges owned by County Highway AgencyCounties which have bridges owned by State Toll AuthorityMost amount of bridges Built based on YearAverage Traffic Less than or equal to 100,000 for Counties with Bridge ConditionAverage Traffic More than 100,000 for Counties with Bridge ConditionImprovement and Bridge Conditions with CountiesConclusionFurther Analysis# loading the packageslibrary(readr)library(tidyverse)library(stringr)library(ggthemr)library(gganimate)library(formattable)# load the theme flat darkggthemr(&amp;quot;flat dark&amp;quot;)# reading the databridges &amp;lt;- read_csv(&amp;quot;baltimore_bridges.</description>
    </item>
    
    <item>
      <title>Week 34 : Thanksgiving </title>
      <link>/post/week_34/week-34-thanksgiving/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_34/week-34-thanksgiving/</guid>
      <description>People who do and do not celebrate ThanksgivingAge DistributionAge with Other FactorsGender DistributionGender with Other FactorsFamily Income DistributionFamily Income with Other FactorsUS Region DistributionConclusionFurther Analysis# Load the packgeslibrary(ggplot2)library(ggthemr)library(stringr)library(gridExtra)library(tidyverse)library(tweenr)library(gganimate)library(kableExtra)library(magrittr)library(knitr)library(readr)#load the dataThanksgiving&amp;lt;-read_csv(&amp;quot;thanksgiving_meals.csv&amp;quot;)# apply the theme grapeggthemr(&amp;quot;grape&amp;quot;)#subset the people who said yes for celebrating thanksgivingThanksgiving_Yes&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;Yes&amp;quot;)#subset the people who said no for celebrating thanksgivingThanksgiving_No&amp;lt;-subset(Thanksgiving,celebrate==&amp;quot;No&amp;quot;)Data set was provided on week 34 for TidyTuesday analysis.</description>
    </item>
    
    <item>
      <title>Week 33 : Malaria Deaths</title>
      <link>/post/week_33/week-33-malaria-deaths/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_33/week-33-malaria-deaths/</guid>
      <description>What I posted in #TidyTuesday on 13th November 2018.SDI Countries with Malaria Death Count RateSaharan Region with Malaria Death Count RateEuropean Countries with Malaria Death Count RateGreat Britain or United Kingdom with Malaria Death Count RateAmerican Region with Malaria Death Count RateAsian Countries with Malaria Death Count RateNorth Africa and Middle East Region with Death Count RateOceania Region with Death Count RateCaribbean and Latin America and Caribbean Countries with Death Count RateConclusionFurther Analysis# load the packageslibrary(ggplot2)library(ggrepel)library(ggthemr)library(magrittr)library(stringr)library(gridExtra)library(readr)library(gganimate)# load the theme flatggthemr(&amp;quot;flat&amp;quot;)#load the data setsmalaria_deaths&amp;lt;-read_csv(&amp;quot;malaria_deaths.</description>
    </item>
    
    <item>
      <title>Week 31 : R and Package Downloads</title>
      <link>/post/week_31/week-31-r-and-package-downloads/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_31/week-31-r-and-package-downloads/</guid>
      <description>IntroductionOperating SystemsR versionsDate versus Operating SystemDownload Size and IP IDConclusionFurther Analysis# load the packageslibrary(readr)library(ggplot2)library(lubridate)library(ggthemr)library(gridExtra)library(magrittr)library(knitr)library(kableExtra)library(readr)# load the datar_downloads_year &amp;lt;- read_csv(&amp;quot;r_downloads_year.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))r_downloads &amp;lt;- read_csv(&amp;quot;r-downloads.csv&amp;quot;, col_types = cols(X1 = col_skip(), date = col_date(format = &amp;quot;%Y-%m-%d&amp;quot;), time = col_time(format = &amp;quot;%H:%M:%S&amp;quot;)))IntroductionTidy Tuesday is a very good move to improve R programming for anyone who is interested in statistics.</description>
    </item>
    
    <item>
      <title>Week 30: Movie Profit</title>
      <link>/post/week_30/week-30-movie-profit/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/week_30/week-30-movie-profit/</guid>
      <description>Movie Profit, Not So ProfitUnderstand Genre and Mpaa Rating on MoviesLets Focus of movies which has zero domestic grossZero Domestic gross Point of ViewGenre and MPAA Rating Point of ViewFinding Outliers in Perspective of Genre and MPAA RatingProduction Budget and Worldwide GrossYears, Months and Days versus Production BudgetConclusionFurther AnalysisMovie Profit, Not So ProfitThis is my first post on Tidy Tuesday and the data-set in question is Movie profit data-set.</description>
    </item>
    
    <item>
      <title>Website-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-website/</link>
      <pubDate>Sun, 30 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-website/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GitHub-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-github/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-github/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CRAN-fitODBOD: fitting Over Dispersed Binomial Outcome Data</title>
      <link>/publication/fitodbod-cran/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/fitodbod-cran/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R Package Development to Model Over Dispersed Binomial Outcome Data with the use of Binomial Mixture Distributions and Alternate Binomial Distributions.</title>
      <link>/publication/4th-year/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/publication/4th-year/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>